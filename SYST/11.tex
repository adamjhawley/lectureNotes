% Created 2019-02-26 Tue 12:39
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\author{Adam Hawley}
\date{\today}
\title{Lecture 11: Segmented \& Paged Memory}
\hypersetup{
 pdfauthor={Adam Hawley},
 pdftitle={Lecture 11: Segmented \& Paged Memory},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.1 (Org mode 9.2)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents


\section{Segmentation}
\label{sec:org9dd22a9}
\subsection{Introduction}
\label{sec:org58c8edb}
Memory-management scheme that supports user view of memory.
A program is a collection of segments where a segment is a logical unit search as: main program, procedure, function, method, object, local variables, global variables, stack, array etc.
Segments have variable sizes.
This approach means that when you are in the main program, only the main program needs to be stored in memory.

\subsection{Addressing with Segmentation}
\label{sec:org93f22d3}
The logical address consists of a tuple: \texttt{<segment-number, offset>}.
The addresses are stored inside a \textbf{segment table} which maps a two-dimensional logical address to a one-dimensional physical address.
\begin{description}
\item[{\texttt{base}}] contains the starting physical addrss where the segments reside in memory
\item[{\texttt{limit}}] specifies the length of the segment
\end{description}
Segment table is kept in memory:
\begin{description}
\item[{\texttt{segment-table base register} (STBR)}] points to the segment table's location in memory
\item[{\texttt{segment-table length register} (STLR)}] indicates number of segments used by a program
\begin{itemize}
\item segment number \texttt{s} is legal if \texttt{s < STLR}
\end{itemize}
\end{description}

\section{Paging}
\label{sec:org213e9a5}
\subsection{Introduction}
\label{sec:org2537079}
Physical address space of a process can be noncontiguous: process is alllocated physical memory whenever the latter is available:
\begin{itemize}
\item avoids external fragmentation
\item avoids problem of varying sized memory chunks
\end{itemize}
Divide physical memory into fixed-sized blocks called \textbf{frames} (size is a power of 2, between 512 bytes and 16 Mbytes).
Then divide the logical memory into blocks of the same size called \textbf{pages} (internal fragmentation is still a minor issue).
\subsection{Costs \& Implementation}
\label{sec:org99ea956}
The OS must:
\begin{itemize}
\item Keep track of all free frames in memory
\item (to run a program of size \emph{N} pages), need to find \emph{N} free frames and load program
\item set up a \textbf{page table} to translate logical to physical addresses --- kept in memory
\begin{description}
\item[{Page-table base register (PTBR)}] Points to the page table
\item[{Page-table length register (PTLR)}] indicates size of the page table
\end{description}
\end{itemize}
\subsection{Address Resolution}
\label{sec:org3cc3f0f}
Assume the logical address space is 2\textsuperscript{m} and that the page size is 2\textsuperscript{n} then the address generated by the CPU is divided into:
\begin{description}
\item[{page number (p)}] used as an index into a \textbf{page table} which contains base address of each page in physical memory
\begin{itemize}
\item size of \textbf{p} is \texttt{m - n} bits
\end{itemize}
\item[{page offset (d)}] combined with base address to define the physical memory address that is sent to the memory unit
\begin{itemize}
\item size of \textbf{d} is \texttt{n} bits
\end{itemize}
\end{description}
\subsection{Internal Fragmentation in Paging}
\label{sec:org56d6de9}
Internal fragmentation happens when the process requires memory which is not a multiple of the page size, when this happens, the last page will cause internal fragmentation as it will not fill the frame.
The worst case fragmentation would be equal to \texttt{1 frame - 1 byte} but average fragmentation is around half a frame size.
\subsubsection{Page Size Trade-Off}
\label{sec:org4708429}
\begin{itemize}
\item Reducing the page size \(\rightarrow\) minimises internal fragmentation
\item Increaseing the page size \(\rightarrow\) less pages needed, reduces page table size (faster, simpler implementation of MM)
\end{itemize}
\subsection{Performance Issues}
\label{sec:org893b5ec}
If the page table is kept in main memory every data/instruction access requires two memory accesses (one for the page table and one for the data/instruction).
The two memory access problem can be solved by the use of a special fast-lookup hardware cache called \textbf{associative memory} or \textbf{translation look-aside buffers (TLBs)}.
The TLB is typically small (64 to 1,024 entries).
Frequently accessed pages will have their frames stored in a TLB.
On a TLB miss, the value of the (missed page-table and frame-number), is loaded into the TLB for faster access next time that address is used (if there is no free TLB entry, replacement policies must be considered).
Some entries can be \textbf{wired down} for permanent fast access.

Address translation \texttt{(p,d)}:
\begin{enumerate}
\item If \texttt{p} is in associative register, get frame \# out
\item Otherwise get frame \# from page table in memory
\end{enumerate}
\subsection{Shared Pages}
\label{sec:org078b0a6}
\subsubsection{Shared Code}
\label{sec:org950e62b}
Processes that are read-only can be shared because there is no danger of modification.
This means that only one copy is needed.
It is similar to the idea of multiple threads sharing the same process space and is also useful for interprocess communication if sharing of read-write pages is allowed.
\subsubsection{Private Code \& Data}
\label{sec:org88ca9e7}
Each process keeps a separate copy of the code and data.
The pages for the private code and data can appear anywhere in the logical space.
\subsection{Page Table Structure}
\label{sec:orgc7af461}
Memory structures for paging can get huge using straight-forward methods:
\begin{itemize}
\item Consider a 32-bit logical address space
\item Page size of 1KB (2\textsuperscript{10})
\item Page table would have 4 million entries (2\textsuperscript{32}/2\textsuperscript{10})
\item If each entry is 4 bytes, page table is of size 16 MB
\begin{itemize}
\item Can be costly
\item Do not want to allocate that contiguously in main memory
\end{itemize}
\end{itemize}
There are several approaches to this problem:
\begin{itemize}
\item Exploit heirarchy
\item 64-bit address spaces require even more sophisticated solutions
\end{itemize}
\subsection{Hierarchical Page Tables}
\label{sec:orgfed115b}
Break up the logical address space into multiple page tables
A simple technique is a two-level page table.
We then page the page-table.

A logical address (on a 32-bit machine with 4K page size) is divided into a page number consisting of 20 bits and a page offset consisting of 12 bits.
Since the page table is paged, the page number is further divided into a 10-bit index \emph{p\textsubscript{1}} into the outer page table and a 10-bit displacement \emph{p\textsubscript{2}} within the page of the inner page table.
\end{document}
