% Created 2019-02-21 Thu 14:11
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\author{Adam Hawley}
\date{\today}
\title{Lecture 10: Introduction to Memory Management}
\hypersetup{
 pdfauthor={Adam Hawley},
 pdftitle={Lecture 10: Introduction to Memory Management},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.1 (Org mode 9.2)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents


\section{Background}
\label{sec:orga76f10a}
\subsection{Introduction}
\label{sec:org78ddd86}
Programs must be brought (from storage) into memory and placed within a process for it to be run.
The main memory and registers are the only storage entities that a CPU can access directly.
The CPU fetches instructions from main memory according to the value of the program counter.
A typical instruction execution cycle looks like this:
\begin{enumerate}
\item Fetch instruction from memory
\item Decode the instruction
\item Operand fetch
\item Possible storage of result in memory
\end{enumerate}

Memory units only see a stream of one of the following:
\begin{itemize}
\item Read request + address
\item Write request + data + address
\end{itemize}
Memory unit does not know how these addresses are generated.
Register access can be done in one CPU clock while completing a memory access may take many cycles of the CPU clock.
In this case the processor needs to \textbf{stall} since it does not have the data required to complete the instruction it is execution.
(In reality not 100\% true because modern CPUs use techniques such as \emph{out-of-order execution}.

The \textbf{Cache} sits between the main memory and CPU registers to mitigate the \emph{stall issue}.
Protection of memory is required to ensure correct operation.
User processes should not be able to access OS memory and one user should not be able to access the memory of another user process.

\subsection{Address Spaces}
\label{sec:org3535c17}
A logical address space is a range of addresses that an operating system makes available to a process.
It is up to the OS to enforce \textbf{memory protection}.
Address space endpoints are a \textbf{base} register (holding the smallest legal physical address of the process in the memory) and a \textbf{limit} register (specifies the size of the address space).
The CPU must check that every memory access generated in user mode is between the \textbf{\texttt{base}} and \textbf{\texttt{base + limit}} for that process.

A program residing on the disk needs to be brought into memory in order to execute.
In general, we do not know a priori where the program is going to reside in memory.

\begin{itemize}
\item Addresses  in the source program are generally symbolic
\begin{itemize}
\item e.g \texttt{count}
\end{itemize}
\item A compiler typically binds these symbolic addresses to relocatable addresses
\begin{itemize}
\item e.g "14 bytes from the beggining of this module"
\end{itemize}
\item \textbf{Linker} or \textbf{loader} will bind relocatable addresses to absolute addresses
\end{itemize}
Addresses are represented in different ways at different stages of a programs life:
\begin{description}
\item[{Compile Time}] If memory location known a priori, \textbf{absolute code} can be generated; must recompile code if starting location changes.
\item[{Load Time}] If memory location is not known at compile time and no hardware support is available, \textbf{relocatable code} must be generated.
\item[{Execution Time}] (Most common in general computing) Binding delayed until run time if the process can be moved during its exectuion from one memory segment to another. This needs hardware support for address maps (e.g base and limit registers).
\end{description}

\subsection{Logical vs. Physical Address Space}
\label{sec:org799edcc}
The concept of a \textbf{logical address space} that is bound to a separate \textbf{physical address space} is central to proper memory management.
\begin{description}
\item[{Logical Address}] Issued by the CPU, within processs address space
\item[{Physical Address}] Address seen by the memory unit.
\end{description}

Logical and physical addresses are:
\begin{itemize}
\item The same in compile-time and load-time address-binding schemes
\item Different in execution-time address-binding schemes.
\end{itemize}
In the latter case, the logical address can be referred to as the virtual address.
\begin{description}
\item[{Logical Address Space}] The set of all logical addresses generated by a program.
\item[{Physical Address Space}] The set of all physical corresponding to a given logical address space.
\end{description}

\subsection{Memory Management}
\label{sec:orgbf3b48d}
A \textbf{Memory Management Unit (MMU)} is a hardware device that at runtime maps logical addresses to physical addresses.
The user program deals with logical addresses and never sees the real physical addresses.
Execution-time binding occurs when reference is made to location in memory.
Logical addresses bound to physical addresses.

\section{Contiguous Memory}
\label{sec:org0ae368c}
\subsection{Single-User Contiguous Memory}
\label{sec:org202f26e}
First computers: all memory assigned to a single job.
Key points: contiguous + entirely assigned.
Advantages:
\begin{itemize}
\item Very simple
\item Address resolution: trivial (physical address = issued address)
\end{itemize}
Disadvantages:
\begin{itemize}
\item Only one job can run at a time so this cannot support multi-programming.
\item Processor unused during I/O operations.
\end{itemize}

\subsection{Fixed Contiguous Partitions}
\label{sec:org17342b3}
OS assigns one partition per process, size of partitions defined at boot time and never changes.
Key point is that it has protection against memory intrusion.
The OS must be assigned its own partition.
Upon starting a new process, the OS has to:
\begin{enumerate}
\item Determine the relevent partition
\item Determine the start address within the active partition
\item Resolve addresses: \texttt{physicalAddress = issuedAddress + fixedBaseRegister}
\end{enumerate}
The problem with this approach is that it is often difficult to choose the right partition sizes which can cause the following.
\textbf{Internal fragmentation} is when a process may require less space than the available partition.
Or process creation may fail even though there may be enough free memory due to wasted memory by small jobs.

\subsection{Dynamic Contiguous Partitions}
\label{sec:org7677b29}
Partition size is selected when the job is loaded.
Address resolution becomes: 

\texttt{physicalAddress = issuedAddress + variableBaseRegister}

This approach alleviated the problems of fixed contiguous partitioning but does not solve it completely.
It is still possible to get \textbf{External Fragmentation} where the OS has to keep track of free partitions.

\subsubsection{Partition Allocation Problem}
\label{sec:org0d0cc34}
How to satisfy a request of size \emph{n} from a list of free partitions?
\begin{description}
\item[{First-fit}] Allocate the first partition that is big enough
\item[{Best-fit}] Allocate the smallest partition that is big enough
\begin{itemize}
\item Must search entire list, unless the list is ordered by size
\item Produces the smallest leftover partition
\end{itemize}
\item[{Worst-fit}] Allocate the largest partition
\begin{itemize}
\item Must also search entire list, unless the list is ordered by size
\item Produces the largest leftover partition
\end{itemize}
\item[{Random}] As it sounds, take a random partition.
\end{description}
There is no clear winner as performance of each depends on the request patterns

\subsubsection{Mitigation of External Fragmentation}
\label{sec:orgba7305a}
External fragmentation can be mitigated by a \textbf{compaction} (or defragmentation) procedure.
This requires \textbf{relocatable partitions} where the base register needs to be changed.
The compaction algorithm needs spare memory space to operate efficiently (i.e to move small partitions out of the way before large partitions can be relocated).
Compaction cannot be performed while I/O is in progress involving memory that is being compacted.
Alternatively, the CPU can latch the process in memory while it is involved in I/O, or do I/O only into OS buffers (i.e double buffering).
\subsection{Swapping}
\label{sec:org540993f}
A process can be \textbf{swapped} temporarily out of memory to a \textbf{backing store}, and then brought back into memory for continued exectution.
This means that the total physical memory space of the processes can exceed physical memory.

The \textbf{Backing Store} is a fast disk large enough to accomodate binaries of all processes.
A major part of swap time is transfer time and the total time is directly proportional to the amount of memory swapped.
\end{document}
